{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['NEO4J_URI'] = os.getenv('NEO4J_URI')\n",
    "os.environ['NEO4J_USERNAME'] = os.getenv('NEO4J_USERNAME')\n",
    "os.environ['NEO4J_PASSWORD'] = os.getenv('NEO4J_PASSWORD')\n",
    "os.environ['together_api_key'] = os.getenv('TOGETHER_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 505.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# loader = TextLoader(\"disease_text/Asthma.txt\")\n",
    "# markdown_document = loader.load()\n",
    "loader = DirectoryLoader('disease_text', glob=\"*.txt\", show_progress=True, loader_cls=TextLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(docs[0].page_content)\n",
    "markdown_document = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [len(x.page_content.split(' ') )for x in markdown_document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers_to_split_on = [\n",
    "    (\"##\", \"Header 1\"),\n",
    "    # (\"###\", \"Header 2\"),\n",
    "    # (\"####\", \"Header 3\"),\n",
    "    # (\"#####\", \"Header 4\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = []\n",
    "\n",
    "for doc in markdown_document:\n",
    "    md_header_splits+=(markdown_splitter.split_text(doc.page_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/77 [09:10<11:37:26, 550.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: ['Disease', 'Symptom', 'Treatment', 'Risk Factor', 'Prevention', 'Complication', 'Epidemiology', 'Research', 'Diagnosis', 'Pathophysiology', 'Genetics', 'Prognosis', 'Prevalence', 'Age Group']\n",
      "Relationships: ['HAS_SYMPTOM', 'HAS_TREATMENT', 'HAS_RISK_FACTOR', 'HAS_PREVENTION', 'CAN_LEAD_TO', 'HAS_EPIDEMIOLOGY', 'HAS_RESEARCH', 'DIAGNOSED_BY', 'AFFECTS', 'INHERITS', 'PROGNOSIS_FOR', 'COMORBID_WITH', 'LEADS_TO', 'EPIDEMIC_IN']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\")\n",
    "# Nodes\n",
    "nodes = [\n",
    "    \"Disease\",\n",
    "    \"Symptom\",\n",
    "    \"Treatment\",\n",
    "    \"Risk Factor\",\n",
    "    \"Prevention\",\n",
    "    \"Complication\",\n",
    "    \"Epidemiology\",\n",
    "    \"Research\",\n",
    "    \"Diagnosis\",\n",
    "    \"Pathophysiology\",\n",
    "    \"Genetics\",\n",
    "    \"Prognosis\",\n",
    "    \"Prevalence\",\n",
    "    \"Age Group\"\n",
    "]\n",
    "\n",
    "# Relationships\n",
    "relationships = [\n",
    "    \"HAS_SYMPTOM\",\n",
    "    \"HAS_TREATMENT\",\n",
    "    \"HAS_RISK_FACTOR\",\n",
    "    \"HAS_PREVENTION\",\n",
    "    \"CAN_LEAD_TO\",\n",
    "    \"HAS_EPIDEMIOLOGY\",\n",
    "    \"HAS_RESEARCH\",\n",
    "    \"DIAGNOSED_BY\",\n",
    "    \"AFFECTS\",\n",
    "    \"INHERITS\",\n",
    "    \"PROGNOSIS_FOR\",\n",
    "    \"COMORBID_WITH\",\n",
    "    \"LEADS_TO\",\n",
    "    \"EPIDEMIC_IN\"\n",
    "]\n",
    "\n",
    "# Example usage:\n",
    "print(\"Nodes:\", nodes)\n",
    "print(\"Relationships:\", relationships)\n",
    "\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm, allowed_nodes = nodes, allowed_relationships=relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(md_header_splits)\n",
    "with open('graph_documents.pkl', 'wb') as file:\n",
    "    pickle.dump(graph_documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('graph_documents.pkl', 'rb') as file:\n",
    "    graph_documents = pickle.load(file)\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser, StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Extract all entities related to persons, diseases, medical conditions, symptoms, and diagnoses from the given USER_QUERY. \n",
    "{format_instructions}\n",
    "\n",
    "USER_QUERY:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['history','user_query'],\n",
    "    template = template,\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asthma', 'High blood pressure', 'Delhi']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"what are some Control methods in Asthma, Vibhanshu has High blood pressure also he lives in delhi\"\n",
    "\n",
    "structured_llm = prompt | llm | parser\n",
    "structured_llm.invoke({'user_query': input_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text\n",
    "    search. It processes the input string by splitting it into words and \n",
    "    appending a similarity threshold (~2 changed characters) to each\n",
    "    word, then combines them using the AND operator. Useful for mapping\n",
    "    entities from user questions to database values, and allows for some \n",
    "    misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = structured_llm.invoke({'user_query': question, 'history':\"\"})\n",
    "    print(entities)\n",
    "    for entity in entities:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, \n",
    "            {limit:1})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS \n",
    "              output\n",
    "              UNION\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS \n",
    "              output\n",
    "            }\n",
    "            RETURN output LIMIT 6\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_questions = [\n",
    "    \"What lifestyle factors can trigger asthma symptoms?\",\n",
    "    \"Why is it important to avoid cigarette smoke for people with asthma?\",\n",
    "    \"Name one recommended lifestyle modification for improving asthma control.\"\n",
    "]\n",
    "\n",
    "medium_questions = [\n",
    "    \"Compare the effectiveness of short-acting and long-acting medications for asthma management.\",\n",
    "    \"Discuss the role of corticosteroids in the long-term control of asthma.\",\n",
    "    \"Explain how avoiding allergens can help in managing asthma symptoms.\"\n",
    "]\n",
    "\n",
    "hard_questions = [\n",
    "    \"Evaluate the effectiveness of cognitive behavioral therapy in improving asthma control and quality of life.\",\n",
    "    \"Discuss the controversies surrounding the use of LABA (Long-Acting Beta Agonists) in children's asthma treatment.\",\n",
    "    \"Explain the potential benefits and risks associated with using macrolide antibiotics in treating severe, refractory asthma.\"\n",
    "]\n",
    "\n",
    "# Combine all questions into one list\n",
    "all_questions = easy_questions + medium_questions + hard_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wheezing', 'treatment']\n",
      "Asthma - HAS_SYMPTOM -> Symptoms\n",
      "Asthma - HAS_SYMPTOM -> Airflow Obstruction\n",
      "Asthma - HAS_SYMPTOM -> Bronchospasms\n",
      "Asthma - HAS_SYMPTOM -> Wheezing\n",
      "Asthma - HAS_SYMPTOM -> Coughing\n",
      "Asthma - HAS_SYMPTOM -> Chest Tightness\n"
     ]
    }
   ],
   "source": [
    "print(structured_retriever('I am having Wheezing treatment'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question: str):\n",
    "    print(f\"Search query: {question}\")\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"You are a helpful Medical assistant and you have to answer user queries from the given context in the form of Structured and Unstructured data.\n",
    "    Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from typing import Tuple, List, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"  # noqa: E501\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatOpenAI(temperature=0)\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY =[]\n",
    "def chat_bot(question, history):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: hi\n",
      "['No entities related to persons', 'diseases', 'medical conditions', 'symptoms', 'or diagnoses were mentioned in the USER_QUERY.']\n",
      "Search query: how many people have asthma?\n",
      "['asthma', 'people']\n",
      "Search query: what are common symptoms of it?\n",
      "['common symptoms']\n",
      "Search query: who are you?\n",
      "['No entities related to persons', 'diseases', 'medical conditions', 'symptoms', 'or diagnoses were mentioned in the given USER_QUERY.']\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def yes_man(message, history):\n",
    "    if message.endswith(\"?\"):\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"Ask me anything!\"\n",
    "\n",
    "gr.ChatInterface(\n",
    "    chat_bot,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Your personal medical assistant\", container=False, scale=7),\n",
    "    title=\"Mediassist 🧑‍⚕️🖨️🤖\",\n",
    "    theme=\"soft\",\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
